{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNMy06XHCocZDFIGcnXgVtL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qudn/Tabular-AL/blob/main/d_ALT_U%2BR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJeGWETSy0B2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec53b1f9"
      },
      "source": [
        "!pip install tabpfn scikit-learn pandas numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8987f59e"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "# You can replace this with the path to your dataset if you have a different one\n",
        "try:\n",
        "    df = pd.read_csv('adult.csv')\n",
        "except FileNotFoundError:\n",
        "    # If the file is not found locally, download from a public source (UCI Machine Learning Repository)\n",
        "    !wget https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data -O adult.csv\n",
        "    df = pd.read_csv('adult.csv', header=None)\n",
        "    # The adult.data file does not have headers, so we add column names manually\n",
        "    df.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n",
        "                  'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',\n",
        "                  'hours-per-week', 'native-country', 'class']\n",
        "\n",
        "display(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daa20529"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "import numpy as np\n",
        "\n",
        "# Handle missing values (represented by '?')\n",
        "df = df.replace(' ?', np.nan)\n",
        "df = df.dropna()\n",
        "\n",
        "# Separate features (X) and target (y)\n",
        "X = df.drop('class', axis=1)\n",
        "y = df['class']\n",
        "\n",
        "# Encode categorical features\n",
        "categorical_cols = X.select_dtypes(include='object').columns\n",
        "encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
        "X[categorical_cols] = encoder.fit_transform(X[categorical_cols])\n",
        "\n",
        "# Split data into training (for active learning) and testing\n",
        "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Create an initial labeled set and an unlabeled pool from the training data\n",
        "initial_labeled_size = 100\n",
        "X_labeled_initial, X_unlabeled_pool, y_labeled_initial, y_unlabeled_pool = train_test_split(\n",
        "    X_train_full, y_train_full, test_size=len(X_train_full) - initial_labeled_size, random_state=42, stratify=y_train_full\n",
        ")\n",
        "\n",
        "print(f\"Initial labeled set size: {len(X_labeled_initial)}\")\n",
        "print(f\"Unlabeled pool size: {len(X_unlabeled_pool)}\")\n",
        "print(f\"Test set size: {len(X_test)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8527da7"
      },
      "source": [
        "from tabpfn import TabPFNClassifier\n",
        "\n",
        "# Initialize TabPFN model\n",
        "# device=\"cpu\" can be used if a GPU is not available\n",
        "tabpfn_model = TabPFNClassifier(device='cuda') # Changed device to 'cuda'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e540db75"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# --- Baseline TabPFN (without Active Learning) ---\n",
        "# Train TabPFN on the initial labeled dataset\n",
        "tabpfn_model.fit(X_labeled_initial, y_labeled_initial)\n",
        "\n",
        "# Evaluate on the test set\n",
        "y_pred_baseline = tabpfn_model.predict(X_test)\n",
        "baseline_accuracy = accuracy_score(y_test, y_pred_baseline)\n",
        "\n",
        "print(f\"Baseline TabPFN Accuracy (initial data only): {baseline_accuracy:.4f}\")\n",
        "\n",
        "# --- Active Learning with Uncertainty Sampling ---\n",
        "\n",
        "# Keep track of labeled and unlabeled data for active learning\n",
        "X_labeled_al = X_labeled_initial.copy()\n",
        "y_labeled_al = y_labeled_initial.copy()\n",
        "X_unlabeled_al = X_unlabeled_pool.copy()\n",
        "y_unlabeled_al = y_unlabeled_pool.copy()\n",
        "\n",
        "# Number of iterations and samples to query in each iteration\n",
        "n_iterations = 10\n",
        "n_query_samples = 50\n",
        "\n",
        "accuracy_history_uncertainty = [baseline_accuracy] # Start with baseline accuracy\n",
        "\n",
        "print(\"\\nStarting Active Learning with Uncertainty Sampling...\")\n",
        "\n",
        "for i in range(n_iterations):\n",
        "    print(f\"Iteration {i+1}/{n_iterations}\")\n",
        "\n",
        "    # Train the model on the current labeled data\n",
        "    tabpfn_model.fit(X_labeled_al, y_labeled_al)\n",
        "\n",
        "    # Get predicted probabilities for the unlabeled pool\n",
        "    # TabPFN can sometimes return probabilities directly, or you might need to use predict_proba\n",
        "    # Check TabPFN documentation for how to get probabilities if predict_proba is not available or works differently\n",
        "    try:\n",
        "        unlabeled_probs = tabpfn_model.predict_proba(X_unlabeled_al)\n",
        "    except AttributeError:\n",
        "        print(\"TabPFNClassifier does not have predict_proba. This active learning strategy requires probability estimates.\")\n",
        "        break # Exit loop if probabilities cannot be obtained\n",
        "\n",
        "    # Calculate uncertainty (e.g., least confidence or margin sampling)\n",
        "    # For least confidence, we take 1 - max(probability)\n",
        "    uncertainty = 1 - np.max(unlabeled_probs, axis=1)\n",
        "\n",
        "    # Select the most uncertain samples\n",
        "    query_indices = np.argsort(uncertainty)[-n_query_samples:]\n",
        "\n",
        "    # Get the selected samples and their true labels from the original unlabeled pool\n",
        "    X_query = X_unlabeled_al.iloc[query_indices]\n",
        "    y_query = y_unlabeled_al.iloc[query_indices] # Get corresponding labels from the full unlabeled set\n",
        "\n",
        "    # Add queried samples to the labeled set\n",
        "    X_labeled_al = pd.concat([X_labeled_al, X_query])\n",
        "    y_labeled_al = pd.concat([y_labeled_al, y_query])\n",
        "\n",
        "    # Remove queried samples from the unlabeled pool\n",
        "    X_unlabeled_al = X_unlabeled_al.drop(X_unlabeled_al.index[query_indices])\n",
        "    y_unlabeled_al = y_unlabeled_al.drop(y_unlabeled_al.index[query_indices])\n",
        "\n",
        "\n",
        "    # Evaluate the model on the test set after adding new samples\n",
        "    y_pred_al = tabpfn_model.predict(X_test)\n",
        "    current_accuracy = accuracy_score(y_test, y_pred_al)\n",
        "    accuracy_history_uncertainty.append(current_accuracy)\n",
        "\n",
        "    print(f\"Accuracy after iteration {i+1}: {current_accuracy:.4f}\")\n",
        "    print(f\"Labeled set size: {len(X_labeled_al)}, Unlabeled pool size: {len(X_unlabeled_al)}\")\n",
        "\n",
        "print(\"\\nActive Learning with Uncertainty Sampling Finished.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "371cd05c"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# --- Baseline TabPFN (without Active Learning) ---\n",
        "# Train TabPFN on the initial labeled dataset\n",
        "tabpfn_model.fit(X_labeled_initial, y_labeled_initial)\n",
        "\n",
        "# Evaluate on the test set\n",
        "y_pred_baseline = tabpfn_model.predict(X_test)\n",
        "baseline_accuracy = accuracy_score(y_test, y_pred_baseline)\n",
        "\n",
        "print(f\"Baseline TabPFN Accuracy (initial data only): {baseline_accuracy:.4f}\")\n",
        "\n",
        "# --- Active Learning with Uncertainty Sampling ---\n",
        "\n",
        "# Keep track of labeled and unlabeled data for active learning\n",
        "X_labeled_al = X_labeled_initial.copy()\n",
        "y_labeled_al = y_labeled_initial.copy()\n",
        "X_unlabeled_al = X_unlabeled_pool.copy()\n",
        "y_unlabeled_al = y_unlabeled_pool.copy()\n",
        "\n",
        "# Number of iterations and samples to query in each iteration\n",
        "n_iterations = 10\n",
        "n_query_samples = 50\n",
        "\n",
        "accuracy_history_uncertainty = [baseline_accuracy] # Start with baseline accuracy\n",
        "\n",
        "print(\"\\nStarting Active Learning with Uncertainty Sampling...\")\n",
        "\n",
        "for i in range(n_iterations):\n",
        "    print(f\"Iteration {i+1}/{n_iterations}\")\n",
        "\n",
        "    # Train the model on the current labeled data\n",
        "    tabpfn_model.fit(X_labeled_al, y_labeled_al)\n",
        "\n",
        "    # Get predicted probabilities for the unlabeled pool\n",
        "    # TabPFN can sometimes return probabilities directly, or you might need to use predict_proba\n",
        "    # Check TabPFN documentation for how to get probabilities if predict_proba is not available or works differently\n",
        "    try:\n",
        "        unlabeled_probs = tabpfn_model.predict_proba(X_unlabeled_al)\n",
        "    except AttributeError:\n",
        "        print(\"TabPFNClassifier does not have predict_proba. This active learning strategy requires probability estimates.\")\n",
        "        break # Exit loop if probabilities cannot be obtained\n",
        "\n",
        "    # Calculate uncertainty (e.g., least confidence or margin sampling)\n",
        "    # For least confidence, we take 1 - max(probability)\n",
        "    uncertainty = 1 - np.max(unlabeled_probs, axis=1)\n",
        "\n",
        "    # Select the most uncertain samples\n",
        "    query_indices = np.argsort(uncertainty)[-n_query_samples:]\n",
        "\n",
        "    # Get the selected samples and their true labels from the original unlabeled pool\n",
        "    X_query = X_unlabeled_al.iloc[query_indices]\n",
        "    y_query = y_unlabeled_al.iloc[query_indices] # Get corresponding labels from the full unlabeled set\n",
        "\n",
        "    # Add queried samples to the labeled set\n",
        "    X_labeled_al = pd.concat([X_labeled_al, X_query])\n",
        "    y_labeled_al = pd.concat([y_labeled_al, y_query])\n",
        "\n",
        "    # Remove queried samples from the unlabeled pool\n",
        "    X_unlabeled_al = X_unlabeled_al.drop(X_unlabeled_al.index[query_indices])\n",
        "    y_unlabeled_al = y_unlabeled_al.drop(y_unlabeled_al.index[query_indices])\n",
        "\n",
        "\n",
        "    # Evaluate the model on the test set after adding new samples\n",
        "    y_pred_al = tabpfn_model.predict(X_test)\n",
        "    current_accuracy = accuracy_score(y_test, y_pred_al)\n",
        "    accuracy_history_uncertainty.append(current_accuracy)\n",
        "\n",
        "    print(f\"Accuracy after iteration {i+1}: {current_accuracy:.4f}\")\n",
        "    print(f\"Labeled set size: {len(X_labeled_al)}, Unlabeled pool size: {len(X_unlabeled_al)}\")\n",
        "\n",
        "print(\"\\nActive Learning with Uncertainty Sampling Finished.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03c2fa36"
      },
      "source": [
        "import random\n",
        "\n",
        "# --- Active Learning with Random Sampling ---\n",
        "\n",
        "# Reset labeled and unlabeled data for random sampling\n",
        "X_labeled_random = X_labeled_initial.copy()\n",
        "y_labeled_random = y_labeled_initial.copy()\n",
        "X_unlabeled_random = X_unlabeled_pool.copy()\n",
        "y_unlabeled_random = y_unlabeled_pool.copy()\n",
        "\n",
        "accuracy_history_random = [baseline_accuracy] # Start with baseline accuracy\n",
        "\n",
        "print(\"\\nStarting Active Learning with Random Sampling...\")\n",
        "\n",
        "for i in range(n_iterations):\n",
        "    print(f\"Iteration {i+1}/{n_iterations}\")\n",
        "\n",
        "    # Train the model on the current labeled data\n",
        "    tabpfn_model.fit(X_labeled_random, y_labeled_random)\n",
        "\n",
        "    # Select random samples from the unlabeled pool\n",
        "    # Ensure we don't try to query more samples than available\n",
        "    n_query = min(n_query_samples, len(X_unlabeled_random))\n",
        "    if n_query == 0:\n",
        "        print(\"Unlabeled pool is empty. Stopping random sampling.\")\n",
        "        break\n",
        "\n",
        "    query_indices_random = random.sample(range(len(X_unlabeled_random)), n_query)\n",
        "\n",
        "    # Get the selected samples and their true labels\n",
        "    X_query_random = X_unlabeled_random.iloc[query_indices_random]\n",
        "    y_query_random = y_unlabeled_random.iloc[query_indices_random]\n",
        "\n",
        "    # Add queried samples to the labeled set\n",
        "    X_labeled_random = pd.concat([X_labeled_random, X_query_random])\n",
        "    y_labeled_random = pd.concat([y_labeled_random, y_query_random])\n",
        "\n",
        "    # Remove queried samples from the unlabeled pool\n",
        "    X_unlabeled_random = X_unlabeled_random.drop(X_unlabeled_random.index[query_indices_random])\n",
        "    y_unlabeled_random = y_unlabeled_random.drop(y_unlabeled_random.index[query_indices_random])\n",
        "\n",
        "    # Evaluate the model on the test set after adding new samples\n",
        "    y_pred_random = tabpfn_model.predict(X_test)\n",
        "    current_accuracy_random = accuracy_score(y_test, y_pred_random)\n",
        "    accuracy_history_random.append(current_accuracy_random)\n",
        "\n",
        "    print(f\"Accuracy after iteration {i+1}: {current_accuracy_random:.4f}\")\n",
        "    print(f\"Labeled set size: {len(X_labeled_random)}, Unlabeled pool size: {len(X_unlabeled_random)}\")\n",
        "\n",
        "print(\"\\nActive Learning with Random Sampling Finished.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15831807"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the accuracy history for each strategy\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.plot(range(len(accuracy_history_uncertainty)), accuracy_history_uncertainty, marker='o', linestyle='-', label='Uncertainty Sampling')\n",
        "plt.plot(range(len(accuracy_history_random)), accuracy_history_random, marker='o', linestyle='-', label='Random Sampling')\n",
        "\n",
        "# Add baseline accuracy as a horizontal line\n",
        "plt.axhline(y=baseline_accuracy, color='r', linestyle='--', label='Baseline (Initial Data Only)')\n",
        "\n",
        "plt.xlabel('Active Learning Iteration')\n",
        "plt.ylabel('Accuracy on Test Set')\n",
        "plt.title('TabPFN Accuracy vs. Active Learning Iterations')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}